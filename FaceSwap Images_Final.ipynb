{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, cv2, dlib, time,math\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Dlib shape detector object to list of tuples\n",
    "def dlibLandmarksToPoints(shape):\n",
    "  points = []\n",
    "  for p in shape.parts():\n",
    "    pt = (p.x, p.y)\n",
    "    points.append(pt)\n",
    "  return points\n",
    "\n",
    "# detect facial landmarks in image\n",
    "def getLandmarks(faceDetector, landmarkDetector, im, FACE_DOWNSAMPLE_RATIO = 1):\n",
    "  points = []\n",
    "  imSmall = cv2.resize(im,None,\n",
    "                       fx=1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "                       fy=1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "                       interpolation = cv2.INTER_LINEAR)\n",
    "  \n",
    "  faceRects = faceDetector(imSmall, 0)\n",
    "  \n",
    "  if len(faceRects) > 0:\n",
    "    maxArea = 0\n",
    "    maxRect = None\n",
    "    # TODO: test on images with multiple faces\n",
    "    for face in faceRects:\n",
    "      if face.area() > maxArea:\n",
    "        maxArea = face.area()\n",
    "        maxRect = [face.left(),\n",
    "                   face.top(),\n",
    "                   face.right(),\n",
    "                   face.bottom()\n",
    "                  ]\n",
    "    \n",
    "    rect = dlib.rectangle(*maxRect)\n",
    "    scaledRect = dlib.rectangle(int(rect.left()*FACE_DOWNSAMPLE_RATIO),\n",
    "                             int(rect.top()*FACE_DOWNSAMPLE_RATIO),\n",
    "                             int(rect.right()*FACE_DOWNSAMPLE_RATIO),\n",
    "                             int(rect.bottom()*FACE_DOWNSAMPLE_RATIO))\n",
    "    \n",
    "    landmarks = landmarkDetector(im, scaledRect)\n",
    "    points = dlibLandmarksToPoints(landmarks)\n",
    "  return points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the vector of indices of 3 points for each triangle\n",
    "def calculateDelaunayTriangles(rect, points):\n",
    "\n",
    "  # Create an instance of Subdiv2D\n",
    "  subdiv = cv2.Subdiv2D(rect)\n",
    "  for p in points:\n",
    "    subdiv.insert((p[0], p[1]))\n",
    "\n",
    "  # Get Delaunay triangulation\n",
    "  triangleList = subdiv.getTriangleList()\n",
    "  delaunayTri = []\n",
    "\n",
    "  for t in triangleList:\n",
    "    pt = []\n",
    "    pt.append((t[0], t[1]))\n",
    "    pt.append((t[2], t[3]))\n",
    "    pt.append((t[4], t[5]))\n",
    "\n",
    "    pt1 = (t[0], t[1])\n",
    "    pt2 = (t[2], t[3])\n",
    "    pt3 = (t[4], t[5])\n",
    "\n",
    "    if rectContains(rect, pt1) and rectContains(rect, pt2) and rectContains(rect, pt3):\n",
    "      ind = []\n",
    "      # Find the index of each vertex in the points list\n",
    "      for j in range(0, 3):\n",
    "        for k in range(0, len(points)):\n",
    "          if(abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0):\n",
    "            ind.append(k)\n",
    "\n",
    "      if len(ind) == 3:\n",
    "        delaunayTri.append((ind[0], ind[1], ind[2]))\n",
    "\n",
    "  return delaunayTri\n",
    "\n",
    "# Check if a point is inside a rectangle\n",
    "def rectContains(rect, point):\n",
    "  if point[0] < rect[0]:\n",
    "    return False\n",
    "  elif point[1] < rect[1]:\n",
    "    return False\n",
    "  elif point[0] > rect[2]:\n",
    "    return False\n",
    "  elif point[1] > rect[3]:\n",
    "    return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply affine transform tp output image\n",
    "def applyAffineTransform(src, srcTri, dstTri, size):\n",
    "  warpMat = cv2.getAffineTransform(np.float32(srcTri), np.float32(dstTri))\n",
    "\n",
    "  dst = cv2.warpAffine(src, warpMat, (size[0], size[1]), None,\n",
    "             flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "  return dst\n",
    "\n",
    "\n",
    "\n",
    "# Warps and alpha blends triangular regions from img1 and img2 to img\n",
    "def warpTriangle(img1, img2, t1, t2):\n",
    "  # Find bounding rectangle for each triangle\n",
    "  r1 = cv2.boundingRect(np.float32([t1]))\n",
    "  r2 = cv2.boundingRect(np.float32([t2]))\n",
    "\n",
    "  t1Rect = []\n",
    "  t2Rect = []\n",
    "  t2RectInt = []\n",
    "\n",
    "  for i in range(0, 3):\n",
    "    t1Rect.append(((t1[i][0] - r1[0]), (t1[i][1] - r1[1])))\n",
    "    t2Rect.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))\n",
    "    t2RectInt.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))\n",
    "    \n",
    "  mask = np.zeros((r2[3], r2[2], 3), dtype=np.float32)\n",
    "  cv2.fillConvexPoly(mask, np.int32(t2RectInt), (1.0, 1.0, 1.0), 16, 0)\n",
    "  img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
    "  size = (r2[2], r2[3])\n",
    "  img2Rect = applyAffineTransform(img1Rect, t1Rect, t2Rect, size)\n",
    "  img2Rect = img2Rect * mask\n",
    "  # Copy  to the output image\n",
    "  img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] * ((1.0, 1.0, 1.0) - mask)\n",
    "  img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] + img2Rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for faceswap 2.760 seconds\n",
      "Time taken for seamless cloning 0.010 seconds\n",
      "Total Time taken 2.770 seconds \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' :\n",
    "\n",
    "  modelPath = \"C:/Users/Mayank Vikram/Documents/Computer Vision/week4/practice/shape_predictor_68_face_landmarks.dat\"\n",
    "    \n",
    "  # initialize the dlib facial landmakr detector\n",
    "  detector = dlib.get_frontal_face_detector()\n",
    "  predictor = dlib.shape_predictor(modelPath)\n",
    "\n",
    "  t = time.time()\n",
    "  # Read images\n",
    "  filename2 = 'C:/Users/Mayank Vikram/Documents/Computer Vision/week5/Practice/Face Swap Photos/Barney Stintion.jpg'\n",
    "  filename1 = 'C:/Users/Mayank Vikram/Documents/Computer Vision/week5/Practice/Face Swap Photos/Pic1 (1).jpg'\n",
    "  \n",
    "  img1 = cv2.imread(filename1)\n",
    "  img2 = cv2.imread(filename2)\n",
    "  img1Warped = np.copy(img2)   \n",
    "  \n",
    "  # Read array of corresponding points\n",
    "  points1 = getLandmarks(detector, predictor, img1)\n",
    "  points2 = getLandmarks(detector, predictor, img2)    \n",
    "  \n",
    "  # Find convex hull\n",
    "  hull1 = []\n",
    "  hull2 = []\n",
    "\n",
    "  hullIndex = cv2.convexHull(np.array(points2), returnPoints=False)\n",
    "        \n",
    "  for i in range(0, len(hullIndex)):\n",
    "    hull1.append(points1[hullIndex[i][0]])\n",
    "    hull2.append(points2[hullIndex[i][0]])\n",
    "  \n",
    "  \n",
    "  # Find delanauy traingulation for convex hull points\n",
    "  sizeImg2 = img2.shape    \n",
    "  rect = (0, 0, sizeImg2[1], sizeImg2[0])\n",
    "   \n",
    "  dt = calculateDelaunayTriangles(rect, hull2)\n",
    "  \n",
    "  if len(dt) == 0:\n",
    "    quit()\n",
    "  \n",
    "  # Apply affine transformation to Delaunay triangles\n",
    "  for i in range(0, len(dt)):\n",
    "    t1 = []\n",
    "    t2 = []\n",
    "    \n",
    "    #get points for img1, img2 corresponding to the triangles\n",
    "    for j in range(0, 3):\n",
    "      t1.append(hull1[dt[i][j]])\n",
    "      t2.append(hull2[dt[i][j]])\n",
    "    \n",
    "    warpTriangle(img1, img1Warped, t1, t2)\n",
    "\n",
    "  print(\"Time taken for faceswap {:.3f} seconds\".format(time.time() - t))\n",
    "  tClone = time.time()\n",
    "\n",
    "  # Calculate Mask for Seamless cloning\n",
    "  hull8U = []\n",
    "  for i in range(0, len(hull2)):\n",
    "    hull8U.append((hull2[i][0], hull2[i][1]))\n",
    "  \n",
    "  mask = np.zeros(img2.shape, dtype=img2.dtype)  \n",
    "  \n",
    "  cv2.fillConvexPoly(mask, np.int32(hull8U), (255, 255, 255))\n",
    "  # find center of the mask to be cloned with the destination image\n",
    "  r = cv2.boundingRect(np.float32([hull2]))    \n",
    "  \n",
    "  center = ((r[0]+int(r[2]/2), r[1]+int(r[3]/2)))\n",
    "      \n",
    "  # Clone seamlessly.\n",
    "  output = cv2.seamlessClone(np.uint8(img1Warped), img2, mask, center, cv2.NORMAL_CLONE)\n",
    "  print(\"Time taken for seamless cloning {:.3f} seconds\".format(time.time() - tClone))\n",
    "\n",
    "  print(\"Total Time taken {:.3f} seconds \".format(time.time() - t))\n",
    "\n",
    "  #cv2.imshow(\"Face Swapped before seamless cloning\", np.uint8(img1Warped))\n",
    "  #cv2.imshow(\"Face Swapped after seamless cloning\", output)\n",
    "\n",
    "  cv2.imwrite(\"faceswap_final.jpg\", output)\n",
    "\n",
    "  #cv2.waitKey(0)\n",
    "  \n",
    "  cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
